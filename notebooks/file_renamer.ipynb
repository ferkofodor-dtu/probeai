{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path = Path().cwd().parent / 'data' / 'raw' / 'array_dataset' / 'test' / 'probed'\n",
    "files = [f for f in path.glob('*.jpg')]\n",
    "\n",
    "for i in range(len(files)):\n",
    "    new_name = path / f'{i}.jpg'\n",
    "    files[i].rename(new_name)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training images: 108\n",
      "Total training labels: 108\n",
      "Total test images: 92\n",
      "Total test labels: 92\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def make_train_test(src, dest, resize=(70, 395)):\n",
    "    defects = [str(f) for f in (src / 'train'/ 'probed').glob('*.jpg')]\n",
    "    non_defects = [str(f) for f in (src / 'train' / 'fresh').glob('*.jpg')]\n",
    "\n",
    "    test_defects = [str(f) for f in (src / 'test' / 'probed').glob('*.jpg')]\n",
    "    test_non_defects = [str(f) for f in (src / 'test' / 'fresh').glob('*.jpg')]\n",
    "\n",
    "    # set seed\n",
    "    np.random.seed(42)\n",
    "    # randomly sample non-defects to match the number of defects\n",
    "    if len(defects) < len(non_defects):\n",
    "        non_defects = np.random.choice(non_defects, len(defects), replace=False)\n",
    "    else:\n",
    "        defects = np.random.choice(defects, len(non_defects), replace=False)\n",
    "\n",
    "\n",
    "    # non_defects = np.random.choice(non_defects, len(defects), replace=False)\n",
    "\n",
    "    defect_images = [cv2.imread(f, cv2.IMREAD_GRAYSCALE) for f in defects]\n",
    "    defect_images = [cv2.resize(img, resize) for img in defect_images]\n",
    "    non_defect_images = [cv2.imread(f, cv2.IMREAD_GRAYSCALE) for f in non_defects]\n",
    "    non_defect_images = [cv2.resize(img, resize) for img in non_defect_images]\n",
    "\n",
    "    test_defect_images = [cv2.imread(f, cv2.IMREAD_GRAYSCALE) for f in test_defects]\n",
    "    test_defect_images = [cv2.resize(img, resize) for img in test_defect_images]\n",
    "    test_non_defect_images = [cv2.imread(f, cv2.IMREAD_GRAYSCALE) for f in test_non_defects]\n",
    "    test_non_defect_images = [cv2.resize(img, resize) for img in test_non_defect_images]\n",
    "\n",
    "    # merge lists\n",
    "    images = defect_images + non_defect_images\n",
    "    test_images = test_defect_images + test_non_defect_images\n",
    "    #images = np.concatenate((np.array(defect_images), np.array(non_defect_images)))\n",
    "\n",
    "    defect_labels = np.ones(len(defects))\n",
    "    non_defect_labels = np.zeros(len(non_defects))\n",
    "    labels = np.concatenate((defect_labels, non_defect_labels))\n",
    "\n",
    "    test_defect_labels = np.ones(len(test_defects))\n",
    "    test_non_defect_labels = np.zeros(len(test_non_defects))\n",
    "    test_labels = np.concatenate((test_defect_labels, test_non_defect_labels))\n",
    "\n",
    "    idx = np.random.permutation(len(images))\n",
    "    images, labels = np.array(images)[idx], labels[idx]\n",
    "\n",
    "    idx = np.random.permutation(len(test_images))\n",
    "    test_images, test_labels = np.array(test_images)[idx], test_labels[idx]\n",
    "\n",
    "    X_train = np.array(images)\n",
    "    X_test = np.array(test_images)\n",
    "    y_train = labels\n",
    "    y_test = test_labels\n",
    "\n",
    "    print('Total training images:', len(X_train))\n",
    "    print('Total training labels:', len(y_train))\n",
    "\n",
    "    print('Total test images:',len(X_test))\n",
    "    print('Total test labels:',len(y_test))\n",
    "    \n",
    "    torch.save(X_train, dest / 'train_data.pt')\n",
    "    torch.save(X_test, dest / 'test_data.pt')\n",
    "    torch.save(y_train, dest / 'train_labels.pt')\n",
    "    torch.save(y_test, dest / 'test_labels.pt')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "path = Path().cwd().parent / 'data' / 'raw' / 'array_dataset'\n",
    "dest = Path().cwd().parent / 'data' / 'processed'\n",
    "\n",
    "X_train, X_test, y_train, y_test = make_train_test(path, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_card_data(src, dest):\n",
    "    images = [str(f) for f in src.glob('*.jpg')]\n",
    "    images = [cv2.imread(f, cv2.IMREAD_GRAYSCALE) for f in images]\n",
    "    images = np.array(images)\n",
    "    torch.save(images, dest / 'card_data.pt')\n",
    "\n",
    "path = Path().cwd().parent / 'data' / 'raw' / 'card_dataset'\n",
    "dest = Path().cwd().parent / 'data' / 'processed'\n",
    "\n",
    "make_card_data(path, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_user_data(src, dest):\n",
    "    images = [str(f) for f in src.glob('*.jpg')]\n",
    "    images = [cv2.imread(f, cv2.IMREAD_GRAYSCALE) for f in images]\n",
    "    images = np.array(images)\n",
    "    torch.save(images, dest / 'user_data.pt')\n",
    "\n",
    "path = Path().cwd().parent / 'data' / 'raw' / 'test_dataset'\n",
    "dest = Path().cwd().parent / 'data' / 'processed'\n",
    "\n",
    "make_user_data(path, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[77, 77, 77, ..., 24, 23, 22],\n",
       "        [76, 75, 75, ..., 22, 21, 20],\n",
       "        [71, 70, 69, ..., 21, 19, 18],\n",
       "        ...,\n",
       "        [43, 37, 32, ..., 44, 44, 45],\n",
       "        [45, 40, 34, ..., 52, 51, 51],\n",
       "        [45, 40, 35, ..., 56, 55, 55]],\n",
       "\n",
       "       [[78, 76, 75, ..., 24, 23, 23],\n",
       "        [74, 73, 73, ..., 22, 21, 20],\n",
       "        [67, 68, 69, ..., 20, 19, 18],\n",
       "        ...,\n",
       "        [45, 39, 33, ..., 47, 47, 46],\n",
       "        [46, 41, 35, ..., 54, 53, 53],\n",
       "        [45, 41, 35, ..., 56, 56, 55]],\n",
       "\n",
       "       [[77, 78, 78, ..., 26, 25, 24],\n",
       "        [77, 77, 77, ..., 24, 22, 21],\n",
       "        [72, 72, 72, ..., 21, 20, 19],\n",
       "        ...,\n",
       "        [38, 34, 31, ..., 44, 44, 45],\n",
       "        [40, 36, 32, ..., 52, 52, 53],\n",
       "        [41, 35, 32, ..., 55, 55, 56]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[81, 80, 79, ..., 29, 28, 26],\n",
       "        [79, 78, 78, ..., 24, 23, 22],\n",
       "        [74, 74, 74, ..., 19, 18, 18],\n",
       "        ...,\n",
       "        [41, 36, 32, ..., 43, 43, 43],\n",
       "        [45, 38, 33, ..., 51, 51, 51],\n",
       "        [44, 37, 32, ..., 55, 55, 54]],\n",
       "\n",
       "       [[78, 78, 78, ..., 29, 28, 25],\n",
       "        [78, 78, 78, ..., 25, 23, 21],\n",
       "        [74, 74, 74, ..., 22, 20, 17],\n",
       "        ...,\n",
       "        [38, 36, 34, ..., 43, 44, 44],\n",
       "        [42, 38, 34, ..., 50, 51, 51],\n",
       "        [43, 37, 33, ..., 54, 55, 55]],\n",
       "\n",
       "       [[79, 78, 78, ..., 25, 24, 23],\n",
       "        [76, 75, 75, ..., 22, 21, 20],\n",
       "        [71, 70, 70, ..., 20, 19, 18],\n",
       "        ...,\n",
       "        [41, 36, 31, ..., 45, 46, 46],\n",
       "        [43, 37, 33, ..., 53, 54, 54],\n",
       "        [42, 37, 33, ..., 57, 57, 57]]], dtype=uint8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(dest / 'user_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, targets, transform=None):\n",
    "        self.data = data\n",
    "        self.targets = torch.LongTensor(targets)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.targets[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            x = cv2.resize(x, (70,395), interpolation = cv2.INTER_AREA)\n",
    "            #x = cv2.Canny(x, 10, 50)\n",
    "\n",
    "            x = self.transform(x)\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "def get_loaders(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    batch_size = 12\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "        transforms.Normalize((0.0), (1.0)),])\n",
    "\n",
    "    gauss = np.array([cv2.GaussianBlur(img, (5, 5), 0) for img in X_train])\n",
    "    #canny = np.array([cv2.Canny(img, 20, 40) for img in gauss])\n",
    "\n",
    "    gauss_test = np.array([cv2.GaussianBlur(img, (5, 5), 0) for img in X_test])\n",
    "    #canny_test = np.array([cv2.Canny(img, 5, 60) for img in gauss_test])\n",
    "\n",
    "    train_dataset = MyDataset(gauss, y_train, transform=transform)\n",
    "    trainloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "    test_dataset = MyDataset(gauss_test, y_test, transform=transform)\n",
    "    testloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    return trainloader, testloader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def dataset_loader(stem):\n",
    "    if stem == 'reference':\n",
    "        path = Path(r'C:\\Users\\fodor52\\Desktop\\probeAI\\reference')\n",
    "        color = 'C0'\n",
    "        X_train, X_test, y_train, y_test = load_train_test(path, plot=False)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.4, random_state=42)\n",
    "    elif stem == 'v21_training':\n",
    "        path = Path(r'C:\\Users\\fodor52\\Desktop\\probeAI\\v21_training')\n",
    "        color = 'C1'\n",
    "\n",
    "        X_train, X_test, y_train, y_test = load_train_test(path, plot=False)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.4, random_state=42)\n",
    "    elif stem == 'training_wlr':\n",
    "        path = Path(r'C:\\Users\\fodor52\\Desktop\\probeAI\\training_wlr')\n",
    "        color = 'C2'\n",
    "\n",
    "        X_train, X_test, y_train, y_test = load_train_test(path, plot=False)\n",
    "        indices = np.random.choice(len(X_test), int(len(X_test)*0.2), replace=False)\n",
    "        indices_train = np.random.choice(len(X_train), int(len(X_train)*0.2), replace=False)\n",
    "\n",
    "        X_train = np.concatenate((X_train, X_test[indices]))\n",
    "        y_train = np.concatenate((y_train, y_test[indices]))\n",
    "\n",
    "        X_test = np.delete(X_test, indices, axis=0)\n",
    "        y_test = np.delete(y_test, indices, axis=0)\n",
    "\n",
    "        X_train = np.delete(X_train, indices_train, axis=0)\n",
    "        y_train = np.delete(y_train, indices_train, axis=0)\n",
    "    else:\n",
    "        raise ValueError('Invalid dataset name')\n",
    "    \n",
    "\n",
    "    print('Total training images:', len(X_train))\n",
    "    print('Total training labels:', len(y_train))\n",
    "\n",
    "    print('Total test images:',len(X_test))\n",
    "    print('Total test labels:',len(y_test))\n",
    "\n",
    "\n",
    "    fig, (ax1,ax2) = plt.subplots(1,2, dpi=300, figsize=(6,2), sharey=True)\n",
    "    sns.histplot(y_train, ax=ax1, bins=10, color=color)\n",
    "    ax1.set_title('Train data distribution')\n",
    "    # add text above each bar\n",
    "    for p in ax1.patches:\n",
    "        if p == ax1.patches[0] or p == ax1.patches[-1]:\n",
    "            ax1.annotate(str(p.get_height()), (p.get_x() +0.01, p.get_height()*0.02), fontsize=4, color='white')\n",
    "    ax1.grid(alpha=0.2)\n",
    "    ax1.set_xticks([0.05, 0.95], [0, 1])\n",
    "    sns.histplot(y_test, ax=ax2, bins=10, color=color)\n",
    "    ax2.set_title('Test data distribution')\n",
    "    ax2.set_xticks([0.05, 0.95], [0, 1])\n",
    "    ax2.grid(alpha=0.2)\n",
    "    for p in ax2.patches:\n",
    "        if p == ax2.patches[0] or p == ax2.patches[-1]:\n",
    "            ax2.annotate(str(p.get_height()), (p.get_x() +0.02, p.get_height()*0.06), fontsize=4, color='white')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "def mnist(src=None):\n",
    "    \"\"\"Return train and test dataloaders for MNIST.\"\"\"\n",
    "    if src is None:\n",
    "        src = Path.cwd() / \"data\" / \"raw\" / \"mnist\"\n",
    "    else:\n",
    "        src = Path(src)\n",
    "\n",
    "    train_data, train_labels = [], []\n",
    "    for i in range(5):\n",
    "        train_data.append(torch.load(src / f\"train_images_{i}.pt\"))\n",
    "        train_labels.append(torch.load(src / f\"train_target_{i}.pt\"))\n",
    "\n",
    "    train_data = torch.cat(train_data, dim=0)\n",
    "    train_labels = torch.cat(train_labels, dim=0)\n",
    "\n",
    "    test_data = torch.load(src / \"test_images.pt\")\n",
    "    test_labels = torch.load(src / \"test_target.pt\")\n",
    "\n",
    "    train_data = train_data.unsqueeze(1)\n",
    "    test_data = test_data.unsqueeze(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
